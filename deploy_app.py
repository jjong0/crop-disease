import streamlit as st
from PIL import Image
import torch
from torchvision import transforms, models
import torch.nn as nn
import os

# ==========================================
# [ì„¤ì •] 6ê°œ ì‘ë¬¼ë³„ ëª¨ë¸ ë° í´ë˜ìŠ¤ ì •ì˜
# ==========================================
# ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë ¬ ìˆœì„œ("10"ì´ "9"ë³´ë‹¤ ë¨¼ì € ì˜¤ëŠ” ë¬¸ìì—´ ì •ë ¬)ì— ë§ì¶¤
CROP_CONFIG = {
    "ê³ ì¶” (Pepper)": {
        "model_file": "pepper_model.pth",
        "classes": ['ê³ ì¶” (ì •ìƒ)', 'ê³ ì¶” (ë§ˆì¼ë“œëª¨í‹€ë°”ì´ëŸ¬ìŠ¤)', 'ê³ ì¶” (ì ë¬´ëŠ¬ë³‘)']  # 2_0, 2_3, 2_4
    },
    "ë”¸ê¸° (Strawberry)": {
        "model_file": "strawberry_model.pth",
        "classes": ['ë”¸ê¸° (ì •ìƒ)', 'ë”¸ê¸° (ì¿ë¹›ê³°íŒ¡ì´ë³‘)', 'ë”¸ê¸° (í°ê°€ë£¨ë³‘)']  # 4_0, 4_7, 4_8
    },
    "ìƒì¶” (Lettuce)": {
        "model_file": "lettuce_model.pth",
        "classes": ['ìƒì¶” (ì •ìƒ)', 'ìƒì¶” (ë…¸ê· ë³‘)', 'ìƒì¶” (ê· í•µë³‘)']  # 5_0, 5_10, 5_9 (ìˆœì„œ ì¤‘ìš”!)
    },
    "ì˜¤ì´ (Cucumber)": {
        "model_file": "cucumber_model.pth",
        "classes": ['ì˜¤ì´ (ì •ìƒ)', 'ì˜¤ì´ (ëª¨ìì´í¬ë°”ì´ëŸ¬ìŠ¤)', 'ì˜¤ì´ (ë…¹ë°˜ëª¨ìì´í¬ë°”ì´ëŸ¬ìŠ¤)']  # 8_0, 8_15, 8_8
    },
    "í† ë§ˆí†  (Tomato)": {
        "model_file": "tomato_model.pth",
        "classes": ['í† ë§ˆí†  (ì •ìƒ)', 'í† ë§ˆí†  (ìê³°íŒ¡ì´ë³‘)', 'í† ë§ˆí†  (í™©í™”ìë§ì´ë°”ì´ëŸ¬ìŠ¤)']  # 11_0, 11_18, 11_19
    },
    "í¬ë„ (Grape)": {
        "model_file": "grape_model.pth",
        "classes": ['í¬ë„ (ì •ìƒ)', 'í¬ë„ (ë…¸ê· ë³‘)']  # 12_0, 12_20
    }
}


# ==========================================
# [í•¨ìˆ˜] ëª¨ë¸ ë¡œë“œ ë° ì „ì²˜ë¦¬
# ==========================================
@st.cache_resource
def load_model_for_crop(crop_name):
    """ì„ íƒí•œ ì‘ë¬¼ì— ë§ëŠ” ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    config = CROP_CONFIG[crop_name]
    model_path = config["model_file"]
    num_classes = len(config["classes"])

    # 1. ëª¨ë¸ êµ¬ì¡° ìƒì„± (MobileNetV3 Small)
    model = models.mobilenet_v3_small(weights=None)
    num_ftrs = model.classifier[3].in_features
    model.classifier[3] = nn.Linear(num_ftrs, num_classes)

    # 2. ê°€ì¤‘ì¹˜ ë¡œë“œ (CPU ëª¨ë“œ)
    if os.path.exists(model_path):
        map_location = torch.device('cpu')
        model.load_state_dict(torch.load(model_path, map_location=map_location))
        model.eval()
        return model
    else:
        st.error(f"ëª¨ë¸ íŒŒì¼({model_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GitHubì— íŒŒì¼ì„ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None


def preprocess_image(image):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (224x224, ì •ê·œí™”)"""
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0)


# ==========================================
# [UI] í™”ë©´ êµ¬ì„±
# ==========================================
st.set_page_config(page_title="ë†ì‘ë¬¼ ë³‘í•´ ì§„ë‹¨ í†µí•© í”Œë«í¼", page_icon="ğŸŒ¿")

st.title("ğŸŒ¿ ë†ì‘ë¬¼ ë³‘í•´ ì§„ë‹¨ í†µí•© í”Œë«í¼")
st.markdown("---")

# 1. ì‘ë¬¼ ì„ íƒí•˜ê¸°
st.subheader("1ï¸âƒ£ ì§„ë‹¨í•  ì‘ë¬¼ì„ ì„ íƒí•˜ì„¸ìš”")
selected_crop = st.selectbox("ì‘ë¬¼ ëª©ë¡", list(CROP_CONFIG.keys()))

# 2. ì‚¬ì§„ ì—…ë¡œë“œ
st.subheader("2ï¸âƒ£ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
uploaded_file = st.file_uploader(f"{selected_crop} ì‚¬ì§„ ì„ íƒ", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    # ì´ë¯¸ì§€ í‘œì‹œ
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='ì—…ë¡œë“œëœ ì´ë¯¸ì§€', use_column_width=True)

    # ì§„ë‹¨ ë²„íŠ¼
    if st.button("ë³‘í•´ ì§„ë‹¨ ì‹œì‘"):
        with st.spinner(f"{selected_crop} ì „ìš© AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):

            # ëª¨ë¸ ë¡œë“œ
            model = load_model_for_crop(selected_crop)

            if model:
                try:
                    # ì¶”ë¡  ì‹¤í–‰
                    input_tensor = preprocess_image(image)
                    with torch.no_grad():
                        outputs = model(input_tensor)
                        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)

                        # ê²°ê³¼ í•´ì„
                        top_prob, top_idx = torch.max(probabilities, 0)
                        class_names = CROP_CONFIG[selected_crop]["classes"]
                        predicted_class = class_names[top_idx]
                        confidence = top_prob.item() * 100

                    # ê²°ê³¼ ì¶œë ¥
                    st.success("âœ… ì§„ë‹¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.metric(label="ì§„ë‹¨ ê²°ê³¼", value=predicted_class)
                    st.write(f"ì‹ ë¢°ë„(í™•ë¥ ): **{confidence:.2f}%**")

                    # í™•ë¥  ë§‰ëŒ€ ê·¸ë˜í”„
                    st.progress(int(confidence))

                    # (ì„ íƒ) ì¶”ê°€ ì¡°ì–¸
                    if "ì •ìƒ" in predicted_class:
                        st.info("ì‘ë¬¼ì´ ê±´ê°•í•´ ë³´ì…ë‹ˆë‹¤! ì£¼ê¸°ì ì¸ ë¬¼ ì£¼ê¸°ì™€ í™˜ê¸°ë¥¼ ìŠì§€ ë§ˆì„¸ìš”.")
                    else:
                        st.warning("ë³‘í•´ê°€ ì˜ì‹¬ë©ë‹ˆë‹¤. ê°€ê¹Œìš´ ë†ì—…ê¸°ìˆ ì„¼í„°ë‚˜ ì „ë¬¸ê°€ì—ê²Œ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")